1、mr为什么采用多进程并发而不是多线程并发？
	优点：方便的对于每一个任务进行控制和调配这是进程的优点
	缺点：就是进程相对比线程来说它会消耗更多的启动时间，也就是说进程的启动要比线程启动要慢很多
	所以MapReduce只适合做一些批量操作，适合高吞吐的情况下不能寄托它太多的实效性。

2、Fiel 归并排序
	block
	dfs.block.size设置block大小默认64M
 
3、inputFormat接口(java开发的)
    mr框架基础类之一
        数据分割split(划分)  map个数依赖split个数
			压缩文件不能split(分割)
			非压缩和sequence文件可split(分割)
        记录读取器	
4、map

5、shuffle(清洗)内存里
	partition分割
	spill(溢出) 内存100MM默认；溢写阈值80M
	combiner(合并)不适合取中值 把reduce提前在map做了
	
6、reduce

7、ulimit系统参数(默认文件打开个数1024)
	# ulimit

8、slot cpu核数-1
	可以用传输压缩文件(不可split)设置MapReduce个数
	
	单机map个数默认2  和文件数、文件大小、块大小、以及split大小有关
	mapred.tasktracker.map.tasks.maximun
		
	
	单机reduce个数默认2
	mapreduce.tasktracker.tasks.reduce.maximun
		可以决定单个tasktracker一次性启动reduce的数目，但是不能决定总的reduce数目。 
	
9、streaming
	优点： 
		开发效率高：可单机调试
		程序运行效率高：可用c/c++
		便于平台进行资源控制: 文件配置 看run.sh
	缺点：
		只能处理文本、二进制不行。可以将二进制进行base64转码成文本
		需要2次数据拷贝和解析(分割)，有一定开销
	输入配置(可以多个文件或单个文件夹)
		INPUT1="a.txt" INPUT2="b.txt"
		-input $INPUT1,$INPUT2 也可以用*、正则等等
		INPUT3="/c"(c是文件夹。会把所有的文件输入)
		-input $INPUT3
	一些配置
		-cacheFule:上传到hdfs分发(大文件)
			"hdfs://master:9000/white_list#ABC"  ABC是white_list重命名
		-cacheArchive:上传到hdfs分发(多文件打包成的压缩包)
			"hdfs://master:9000/bao.tar.gz#ABC"
		-file:本地分发(要求文件小)
	reduce个数
		-reducer "mapred.reduce.tasks=1"
	数据压缩传输(减少宽带资源浪费)：
		map配置
		-jobconf "mapred.compress.map.output=true"
		-jobconf "mapred.map.output.compression.codec=org.apache.hadoop.io.compress.GzipCodec"
		reduce配置
		-jobconf "mapred.output.compress=true"
		-jobconf "mapred.output.compression.codec=org.apache.hadoop.io.compress.GzipCodec"
	排序配置 默认字符排序
		前2个字段作为key
		-jobconf "stream.num.map.output.key.fields=2" \
		第一列排序
		-jobconf "num..key.fields.for.partition=1" \
		-partitioner org.apache.hadoop.mapred.lib.keyFieldBasedPartitioner
		
10、杀死任务
	./hadoop job -kill job_20180101_xxx(job的id)


	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	




